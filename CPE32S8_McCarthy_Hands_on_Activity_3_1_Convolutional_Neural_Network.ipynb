{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "historic-trainer",
      "metadata": {
        "id": "historic-trainer"
      },
      "source": [
        "# Activity 2.1 : Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "olive-manner",
      "metadata": {
        "id": "olive-manner"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to introduce how to build a convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "happy-transport",
      "metadata": {
        "id": "happy-transport"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train convolutional neural network\n",
        "* Evaluate the accuracy and loss of the model using convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "leading-providence",
      "metadata": {
        "id": "leading-providence"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "* CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "literary-trail",
      "metadata": {
        "id": "literary-trail"
      },
      "source": [
        "#### Procedures\n",
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "stretch-active",
      "metadata": {
        "id": "stretch-active"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "collaborative-seating",
      "metadata": {
        "id": "collaborative-seating"
      },
      "source": [
        "* Shuffle the data\n",
        "* Split the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "modular-springer",
      "metadata": {
        "id": "modular-springer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7782222-1c46-4235-bbec-c04de1336a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "female-carolina",
      "metadata": {
        "id": "female-carolina"
      },
      "source": [
        "Check the image size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "alleged-stephen",
      "metadata": {
        "id": "alleged-stephen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7373b48b-528b-4916-d8bb-6f6143d28af6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "x_train[444].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conscious-twenty",
      "metadata": {
        "id": "conscious-twenty"
      },
      "source": [
        "Visualize one of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "positive-creation",
      "metadata": {
        "id": "positive-creation",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "da167ea3-7b2a-44e2-d742-4350bab7944d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(y_train[444])\n",
        "plt.imshow(x_train[444]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "animated-rotation",
      "metadata": {
        "id": "animated-rotation"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "severe-filing",
      "metadata": {
        "id": "severe-filing"
      },
      "source": [
        "Instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "genetic-centre",
      "metadata": {
        "id": "genetic-centre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ab527c-3753-4ba8-d364-cc2d855404c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_train[444]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "detected-education",
      "metadata": {
        "id": "detected-education"
      },
      "source": [
        "Convert to float and scale the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "familiar-damages",
      "metadata": {
        "id": "familiar-damages"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bizarre-smith",
      "metadata": {
        "id": "bizarre-smith"
      },
      "source": [
        "Build a CNN using Keras Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "understanding-milan",
      "metadata": {
        "id": "understanding-milan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0b2619-0ca7-470c-a65d-a198e3c79b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 16, 32)        2432      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 3, 3, 32)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 288)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               147968    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181162 (707.66 KB)\n",
            "Trainable params: 181162 (707.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baking-portable",
      "metadata": {
        "id": "baking-portable"
      },
      "source": [
        "* Use batch size of 32\n",
        "* Initiate RMSprop optimizer\n",
        "* Train the model using RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "removed-memorial",
      "metadata": {
        "id": "removed-memorial",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b63c23c-35c6-41d3-c1df-f765fa759124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 44s 27ms/step - loss: 1.6943 - accuracy: 0.3818 - val_loss: 1.4342 - val_accuracy: 0.4874\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.4454 - accuracy: 0.4830 - val_loss: 1.2852 - val_accuracy: 0.5356\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.3690 - accuracy: 0.5130 - val_loss: 1.2471 - val_accuracy: 0.5550\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 1.3179 - accuracy: 0.5345 - val_loss: 1.2104 - val_accuracy: 0.5754\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2890 - accuracy: 0.5462 - val_loss: 1.4063 - val_accuracy: 0.5198\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2731 - accuracy: 0.5577 - val_loss: 1.2509 - val_accuracy: 0.5653\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 1.2636 - accuracy: 0.5627 - val_loss: 1.1693 - val_accuracy: 0.5910\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2533 - accuracy: 0.5680 - val_loss: 1.1273 - val_accuracy: 0.6019\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 1.2621 - accuracy: 0.5674 - val_loss: 1.2357 - val_accuracy: 0.5796\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 1.2653 - accuracy: 0.5721 - val_loss: 1.3744 - val_accuracy: 0.5505\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2632 - accuracy: 0.5699 - val_loss: 1.1495 - val_accuracy: 0.6157\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2607 - accuracy: 0.5717 - val_loss: 1.3084 - val_accuracy: 0.5742\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2732 - accuracy: 0.5698 - val_loss: 1.3077 - val_accuracy: 0.5747\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 1.2844 - accuracy: 0.5664 - val_loss: 1.2508 - val_accuracy: 0.5871\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2916 - accuracy: 0.5656 - val_loss: 1.2070 - val_accuracy: 0.5948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b7528deb5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_lKTom4AhWK",
        "outputId": "5bb80033-9ca3-419e-8bb0-3fc7a9de76b3"
      },
      "id": "6_lKTom4AhWK",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.2069872617721558\n",
            "Test accuracy: 0.5947999954223633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jewish-lambda",
      "metadata": {
        "id": "jewish-lambda"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "southeast-theater",
      "metadata": {
        "id": "southeast-theater"
      },
      "source": [
        "* Build a more complicated model with the following pattern:\n",
        "Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "\n",
        "* Use strides of 1 for all convolutional layers.\n",
        "\n",
        "* Write the number of parameters of your model  and compare it to the previous model\n",
        "\n",
        "* Train it for 5 epochs. Commpare the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
        "\n",
        "* Use different structures and run times, and see how accurate your model can be."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#New model\n",
        "model_2 = Sequential()\n",
        "\n",
        "# First conv\n",
        "model_2.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "# Second conv\n",
        "model_2.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "# First MaxPool\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Third conv\n",
        "model_2.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "# Fourth conv\n",
        "model_2.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "# Second MaxPool\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten\n",
        "model_2.add(Flatten())\n",
        "\n",
        "# Dense\n",
        "model_2.add(Dense(512))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "\n",
        "# Final layer\n",
        "model_2.add(Dense(num_classes))\n",
        "model_2.add(Activation('softmax'))\n"
      ],
      "metadata": {
        "id": "vjOhoIMkG2Ef"
      },
      "id": "vjOhoIMkG2Ef",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write the number of parameters of your model and compare it to the previous model\n",
        "model_1.summary()\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG9gZ9053erg",
        "outputId": "ba811cad-00c1-42a5-d92a-55bf99c05924"
      },
      "id": "IG9gZ9053erg",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 16, 32)        2432      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 3, 3, 32)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 288)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               147968    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181162 (707.66 KB)\n",
            "Trainable params: 181162 (707.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               4194816   \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4460106 (17.01 MB)\n",
            "Trainable params: 4460106 (17.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Since there are more layers, the parameters in model 2 exceed model 1.</b>"
      ],
      "metadata": {
        "id": "kCj7M5v6J6FT"
      },
      "id": "kCj7M5v6J6FT"
    },
    {
      "cell_type": "code",
      "source": [
        "#Train for 5 epochs and compare the training time, loss and accuracy numbers\n",
        "batch_size = 32\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEKghc9U4eC_",
        "outputId": "e49b4979-6986-4102-b237-5aba22d8a940"
      },
      "id": "zEKghc9U4eC_",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 829s 530ms/step - loss: 1.5018 - accuracy: 0.4626 - val_loss: 1.0919 - val_accuracy: 0.6114\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 830s 531ms/step - loss: 0.9657 - accuracy: 0.6648 - val_loss: 0.9168 - val_accuracy: 0.6848\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 826s 528ms/step - loss: 0.7984 - accuracy: 0.7315 - val_loss: 0.8430 - val_accuracy: 0.7118\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 833s 533ms/step - loss: 0.7382 - accuracy: 0.7550 - val_loss: 0.8024 - val_accuracy: 0.7501\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 824s 527ms/step - loss: 0.7288 - accuracy: 0.7644 - val_loss: 0.7895 - val_accuracy: 0.7484\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b74f4c39960>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score1 = model_1.evaluate(x_test, y_test, verbose=0)\n",
        "print('Model 1 Test loss:', score1[0])\n",
        "print('Model 1 Test accuracy:', score1[1])\n",
        "\n",
        "score2 = model_2.evaluate(x_test, y_test, verbose=0)\n",
        "print('Model 2 Test loss:', score2[0])\n",
        "print('Model 2 Test accuracy:', score2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UfYRYIiJMqu",
        "outputId": "19235e44-6657-4d47-f217-644761825ea8"
      },
      "id": "1UfYRYIiJMqu",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Test loss: 1.2069872617721558\n",
            "Model 1 Test accuracy: 0.5947999954223633\n",
            "Model 2 Test loss: 0.789497971534729\n",
            "Model 2 Test accuracy: 0.7483999729156494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Since there are more parameters and convolutional layers, the second model is more accurate compared to the first one. One drawback is that since there are more layers and parameters, it takes significantly longer to train.</b>"
      ],
      "metadata": {
        "id": "6ddYcLsYJlxg"
      },
      "id": "6ddYcLsYJlxg"
    },
    {
      "cell_type": "markdown",
      "id": "compact-still",
      "metadata": {
        "id": "compact-still"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "desirable-jackson",
      "metadata": {
        "id": "desirable-jackson"
      },
      "source": [
        "#In this laboratory activity, we learned about CNN or Convolutional Neural Networks with the use of Keras. A CNN essentially uses layers of fileters to break down an image into smaller parts or features. We have learned about convolutional layers, pooling layers, and how they contribute to the CNN model. We also compared models in the activity that differ in layers, strides, and different parameters, to see which is more accurate. All in all, CNN is a more complex neural network and can provide a better output/prediction compared to a simpler one."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}